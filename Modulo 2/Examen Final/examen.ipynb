{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed, compute\n",
    "\n",
    "import os \n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample = pd.read_csv('data/Credit Cards Transactions/credit_card_transactions-ibm_v2.csv', nrows= 500_000)\n",
    "card_info_sample = pd.read_csv('/home/eacs/Documents/Diplomado DS/Modulo 2/Examen Final/data/Credit Cards Transactions/sd254_cards.csv')\n",
    "user_info_sample = pd.read_csv('/home/eacs/Documents/Diplomado DS/Modulo 2/Examen Final/data/Credit Cards Transactions/sd254_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de la información\n",
    "Primero limpiaremos transactions con el uso de la muestra para poder tener una idea de que es lo que debería tener cada columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no tiene estas columnas no sería posible hacer un análisis de la información por lo que si no las tienen las eliminaremos\n",
    "transactions_sample.dropna(subset= ['User', 'Card', 'Month', 'Day', 'Is Fraud?'], axis= 0, inplace= True)\n",
    "# Amount pasamos a numérico\n",
    "transactions_sample['Amount'] = transactions_sample['Amount'].replace({'\\$':''}, regex=True).astype('float')\n",
    "# Por la información sabemos que si Errors es NaN entonces no se tiene que borrar porque significa que no hay error\n",
    "transactions_sample['Errors?'].fillna('0', inplace= True)\n",
    "# En la localización de la venta los valores de NaN puede que signifiquen que no esté correctamente registrado pero eso puede ser información que se puede usar\n",
    "transactions_sample['Zip'] = transactions_sample['Zip'].astype('object')\n",
    "transactions_sample[['Merchant Name', 'Merchant City', 'Merchant State', 'Zip']] = transactions_sample[['Merchant Name', 'Merchant City',\n",
    "                                                                                                        'Merchant State', 'Zip']].replace({'NaN':'No registrado',\n",
    "                                                                                                                                            np.nan : 'No registrado'})\n",
    "# Pasamos los valores de Tiempo para poder hacer agrupaciones con ellos\n",
    "transactions_sample['Hour'] = pd.DatetimeIndex(transactions_sample['Time']).hour\n",
    "transactions_sample.drop('Time', axis= 1, inplace= True)\n",
    "\n",
    "transactions_sample['Fraud'] = transactions_sample['Is Fraud?'].replace({'No': 0, 'Yes':1})\n",
    "transactions_sample.drop('Is Fraud?', axis= 1, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "cols_to_label = ['Use Chip', 'Merchant Name','Errors?']\n",
    "l_enc = LabelEncoder()\n",
    "\n",
    "for col in cols_to_label:\n",
    "    transactions_sample[col] = l_enc.fit_transform(transactions_sample[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos datos de la tarjeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_info_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_label = ['Card Brand', 'Card Type', 'Has Chip', 'Cards Issued', 'Year PIN last Changed', 'Card on Dark Web']\n",
    "l_enc = LabelEncoder()\n",
    "\n",
    "for col in cols_to_label:\n",
    "    card_info_sample[col] = l_enc.fit_transform(card_info_sample[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_info_sample['Expires'] = pd.to_datetime(card_info_sample['Expires'], format= '%m/%Y')\n",
    "card_info_sample['Acct Open Date'] = pd.to_datetime(card_info_sample['Acct Open Date'], format= '%m/%Y')\n",
    "card_info_sample['days_until_expire'] = (card_info_sample['Expires'] - card_info_sample['Acct Open Date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_info_sample['Credit Limit'] = card_info_sample['Credit Limit'].replace({'\\$':''}, regex=True).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample = transactions_sample.merge(card_info_sample, how= 'inner', left_on= ['User', 'Card'], right_on= ['User', 'CARD INDEX'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porcentaje del gasto comparado con su línea de crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample['pct_Limit_amount'] = transactions_sample['Amount'] / transactions_sample['Credit Limit']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gastos promedio para cada tipo de MCC mensual por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_mcc = transactions_sample.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'MCC', values= 'Amount', aggfunc= 'mean').fillna(0)\n",
    "new_columns = {col: f'MCC_{col}' for col in count_mcc.columns}\n",
    "count_mcc = count_mcc.rename(columns= new_columns)\n",
    "count_mcc.reset_index(inplace= True)\n",
    "transactions_sample = transactions_sample.merge(count_mcc, on=['User', 'Card', 'Year', 'Month'], how= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_state = transactions_sample.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'Merchant State', values= 'Amount', aggfunc= 'sum').fillna(0)\n",
    "new_columns = {col: f'Merch_State_{col}' for col in count_state.columns}\n",
    "count_state = count_state.rename(columns= new_columns)\n",
    "count_state.reset_index(inplace= True)\n",
    "transactions_sample = transactions_sample.merge(count_state, on=['User', 'Card', 'Year', 'Month'], how= 'inner')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora los datos que se necesitan de cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_label = ['Gender']\n",
    "l_enc = LabelEncoder()\n",
    "\n",
    "for col in cols_to_label:\n",
    "    user_info_sample[col] = l_enc.fit_transform(user_info_sample[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_sample.dropna(subset= ['Person', 'City', 'State', 'Zipcode'], inplace= True, axis= 0)\n",
    "user_info_sample.fillna('NoRecod', inplace= True)\n",
    "\n",
    "user_info_sample['Per Capita Income - Zipcode'] = user_info_sample['Per Capita Income - Zipcode'].replace({'\\$':''}, regex=True).astype('float')\n",
    "user_info_sample['Yearly Income - Person'] = user_info_sample['Yearly Income - Person'].replace({'\\$':''}, regex=True).astype('float')\n",
    "user_info_sample['Total Debt'] = user_info_sample['Total Debt'].replace({'\\$':''}, regex=True).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample = transactions_sample.merge(user_info_sample, left_on= 'User', right_index= True, how= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['User', 'Card', 'Year', 'Month', 'Day', 'Amount']\n",
    "\n",
    "mc_cols = [x for x in transactions_sample.columns if x[0:4]== 'MCC_']\n",
    "merch_cols = [x for x in transactions_sample.columns if x[0:6]== 'Merch_']\n",
    "\n",
    "cat_cols = ['Use Chip', 'Merchant Name', 'Errors?','Card Brand',\n",
    " 'Card Type','Has Chip','Year PIN last Changed', 'Gender',]\n",
    "cont_cols = ['Current Age', 'Retirement Age', 'Per Capita Income - Zipcode', 'Yearly Income - Person', 'Total Debt','FICO Score', 'Num Credit Cards']\n",
    "\n",
    "created_num = ['days_until_expire', 'pct_Limit_amount', 'InState', 'InCity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample['InState'] = transactions_sample.apply(lambda x: 1 if x['State'] == x['Merchant State'] else 0, axis= 1)\n",
    "transactions_sample['InCity'] = transactions_sample.apply(lambda x: 1 if x['City'] == x['Merchant City'] else 0, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_sample = transactions_sample[id_cols + mc_cols + merch_cols + cat_cols + cont_cols + created_num + ['Fraud']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primeras pruebas de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = transactions_sample[id_cols + mc_cols + merch_cols + cat_cols + cont_cols + created_num]\n",
    "y = transactions_sample['Fraud']\n",
    "\n",
    "tl = TomekLinks(sampling_strategy= 'auto')\n",
    "\n",
    "Xt, Xv, yt, yv = train_test_split(X,y, train_size = 0.7)\n",
    "Xt, yt = tl.fit_resample(Xt,yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgclas = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgclas.fit(Xt, yt)\n",
    "predicted = xgclas.predict(Xv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true = yv, y_pred= predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(yt, xgclas.predict(Xt)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejecución distribuida\n",
    "Para poder ejecutar en toda la información usaremos Dask para poder distribuir los procesos y no muera el kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = 'data/'\n",
    "files = [file for file in os.listdir(dataPath)]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = dd.read_csv(dataPath + files[2], dtype={'Errors?': 'object'})\n",
    "user_info = dd.read_csv(dataPath + files[0])\n",
    "card_info = dd.read_csv(dataPath + files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"Date\"] = dd.to_datetime(transactions[[\"Year\", \"Month\", 'Day']])\n",
    "max_date = transactions.Date.max().compute()\n",
    "min_date = transactions.Date.min().compute()\n",
    "print(min_date)\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions[transactions.Date >= '2000-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = transactions.Date.max().compute()\n",
    "min_date = transactions.Date.min().compute()\n",
    "print(min_date)\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = dd.merge(transactions, user_info, left_on= 'User',right_index= True, how= 'left')\n",
    "union = dd.merge(union, card_info, left_on= 'User',right_on= 'User', how= 'left')\n",
    "union.head(2).to_clipboard()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si no tiene estas columnas no sería posible hacer un análisis de la información\n",
    "union = union.dropna(subset= [\n",
    "    'User', 'Card', 'Month', 'Day', 'Is Fraud?', # De Transactions\n",
    "    'Person', 'City', 'State', 'Zipcode', # De user_info\n",
    "    'Card Brand', 'Card Type', 'Has Chip', 'Cards Issued', 'Credit Limit', 'Expires', 'Acct Open Date' # De union\n",
    "    ])\n",
    "\n",
    "# Amount pasamos a numérico\n",
    "union = union.assign(\n",
    "    Amount=union['Amount'].str.replace('$', '').astype('float64'),\n",
    "    Credit_Limit = union['Credit Limit'].str.replace('$', '').astype('float64'),\n",
    "    Total_Debt = union['Total Debt'].str.replace('$', '').astype('float64'),\n",
    "    Per_Capita_Income_Zipcide = union['Per Capita Income - Zipcode'].str.replace('$', '').astype('float64'),\n",
    "    Yearly_Income_Person = union['Yearly Income - Person'].str.replace('$', '').astype('float64')\n",
    ")\n",
    "\n",
    "\n",
    "union = union.drop(\n",
    "    ['Credit Limit', 'Total Debt', 'Per Capita Income - Zipcode', 'Yearly Income - Person'],\n",
    "    axis = 1)\n",
    "\n",
    "\n",
    "# Formato de fecha\n",
    "union = union.assign(\n",
    "    Acct_Open_Date = dd.to_datetime(union['Acct Open Date'], format= '%m/%Y'),\n",
    "    Expires= dd.to_datetime(union['Expires'], format= '%m/%Y'),\n",
    "    )\n",
    "union = union.drop(\n",
    "    ['Acct Open Date'],\n",
    "    axis = 1)\n",
    "\n",
    "# Cambio de formatos\n",
    "union = union.assign(\n",
    "    Zip = union['Zip'].astype('object'),\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# Remplazar datos faltantes\n",
    "union = union.assign(\n",
    "    Merchant_Name = union['Merchant Name'].replace(np.nan, 'No registrado'),\n",
    "    Merchant_City = union['Merchant City'].replace(np.nan, 'No registrado'),\n",
    "    Merchant_State = union['Merchant State'].replace(np.nan, 'No registrado'),\n",
    "    Zip = union['Zip'].replace(np.nan, 'No registrado')\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "union = union.assign(\n",
    "    Erros= union['Errors?'].fillna('0'),\n",
    "    Fraud= union['Is Fraud?'].map({'No': 0, 'Yes': 1})\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "union.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creación de variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dias desde el último fraude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union[\"Date\"] = dd.to_datetime(union[[\"Year\", \"Month\", 'Day']])\n",
    "\n",
    "# Find the last fraud date for each user and card combination\n",
    "last_fraud = union[union[\"Fraud\"] == True].groupby([\"User\", \"Card\"])[\"Date\"].max()\n",
    "\n",
    "# Create a new column to track the number of days since a fraud happened\n",
    "def add_days_since_fraud(row):\n",
    "    if row[\"Fraud\"] == True:\n",
    "        return 0\n",
    "    else:\n",
    "        user = row[\"User\"]\n",
    "        card = row[\"Card\"]\n",
    "        if (user, card) in last_fraud:\n",
    "            return (row[\"Date\"] - last_fraud[(user, card)]).days\n",
    "    return np.nan\n",
    "\n",
    "union[\"Days Since Fraud\"] = union.map_partitions(lambda union: union.apply(add_days_since_fraud, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date = union.Date.max().compute()\n",
    "print(max_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_days_until_expire(df):\n",
    "    df['days_until_expire'] = (df['Expires'] - df['Acct_Open_Date']).dt.days\n",
    "    return df\n",
    "\n",
    "union = union.map_partitions(calc_days_until_expire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pct_amount_limit(df):\n",
    "    df['pct_limit_amount'] = df['Amount'] / df['Credit_Limit']\n",
    "    return df\n",
    "\n",
    "union = union.map_partitions(calc_pct_amount_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union['InState'] = union.apply(lambda x: 1 if x['State'] == x['Merchant State'] else 0, axis= 1, meta= (None, 'int64'))\n",
    "union['InCity'] = union.apply(lambda x: 1 if x['City'] == x['Merchant City'] else 0, axis= 1, meta= (None, 'int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['User', 'Card', 'Year', 'Month', 'Day', 'Amount']\n",
    "\n",
    "cat_cols = ['Use Chip', 'Merchant Name', 'Errors','Card Brand',\n",
    " 'Card Type','Has Chip','Year PIN last Changed', 'Gender',]\n",
    "cont_cols = ['Current Age', 'Retirement Age', 'Per Capita Income - Zipcode', 'Yearly Income - Person', 'Total Debt','FICO Score', 'Num Credit Cards']\n",
    "\n",
    "created_num = ['days_until_expire', 'pct_limit_amount', 'InState', 'InCity']\n",
    "\n",
    "\n",
    "columns_use = [id_cols + cat_cols + cont_cols + created_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_columns(df):\n",
    "    cols_to_label = [\n",
    "        'Use Chip', 'Merchant Name','Errors', \n",
    "        'Card Brand', 'Card Type', 'Has Chip', 'Cards Issued', 'Year PIN last Changed', 'Card on Dark Web',\n",
    "        'Gender'\n",
    "        ]\n",
    "\n",
    "    l_enc = LabelEncoder()\n",
    "\n",
    "    for col in cols_to_label:\n",
    "        df = df.assign(**{col: l_enc.fit_transform(df[col])})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se hará primero un modelo por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_for_user = []\n",
    "unique_users = union.User.compute().unique()\n",
    "print(len(unique_users))\n",
    "for user in unique_users:\n",
    "    user_df = union[union.User == user].map_partitions(lambda df: df.loc[df.User == user])\n",
    "\n",
    "    # Pivote de tipo giro de la compra\n",
    "    count_mcc = user_df.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'MCC', values= 'Amount', aggfunc= 'mean')\n",
    "    new_columns = {col: f'MCC_{col}' for col in count_mcc.columns}\n",
    "    count_mcc = count_mcc.rename(columns= new_columns)\n",
    "    count_mcc.reset_index(inplace= True)\n",
    "    user_df = user_df.merge(count_mcc, on=['User', 'Card', 'Year', 'Month'], how= 'inner')\n",
    "    print(new_columns)\n",
    "    # Pivote de estado de compras\n",
    "    count_state = user_df.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'Merchant State', values= 'Amount', aggfunc= 'sum').fillna(0)\n",
    "    new_columns = {col: f'Merch_State_{col}' for col in count_state.columns}\n",
    "    count_state = count_state.rename(columns= new_columns)\n",
    "    count_state.reset_index(inplace= True)\n",
    "    user_df = user_df.merge(count_state, on=['User', 'Card', 'Year', 'Month'], how= 'inner')\n",
    "    print(new_columns)\n",
    "\n",
    "    # Agregamos las variables\n",
    "    mc_cols = [x for x in user_df.columns if x[0:4]== 'MCC_']\n",
    "    merch_cols = [x for x in user_df.columns if x[0:6]== 'Merch_']\n",
    "\n",
    "    columns_use = [columns_use + mc_cols + merch_cols]\n",
    "\n",
    "    dd_for_user.append(user_df)\n",
    "    print(mc_cols, merch_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = union.groupby(\"User\")\n",
    "def process_group(user, group):\n",
    "    # Pivote de tipo giro de la compra\n",
    "    count_mcc = group.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'MCC', values= 'Amount', aggfunc= 'mean')\n",
    "    new_columns = {col: f'MCC_{col}' for col in count_mcc.columns}\n",
    "    count_mcc = count_mcc.rename(columns= new_columns)\n",
    "    count_mcc.reset_index(inplace= True)\n",
    "    group = group.merge(count_mcc, on=['User', 'Card', 'Year', 'Month'], how= 'inner')\n",
    "    # Pivote de estado de compras\n",
    "    count_state = group.pivot_table(index= ['User', 'Card', 'Year', 'Month'], columns= 'Merchant State', values= 'Amount', aggfunc= 'sum').fillna(0)\n",
    "    new_columns = {col: f'Merch_State_{col}' for col in count_state.columns}\n",
    "    count_state = count_state.rename(columns= new_columns)\n",
    "    count_state.reset_index(inplace= True)\n",
    "    group = group.merge(count_state, on=['User', 'Card', 'Year', 'Month'], how= 'inner')\n",
    "    # Agregamos las variables\n",
    "    mc_cols = [x for x in group.columns if x[0:4]== 'MCC_']\n",
    "    merch_cols = [x for x in group.columns if x[0:6]== 'Merch_']\n",
    "    columns_use = [columns_use + mc_cols + merch_cols]\n",
    "    return group\n",
    "    \n",
    "dd_for_user = [dask.delayed(process_group)(user, group) for user, group in grouped]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_hesh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d40a156c0a69e072bf69323100957728386abbf036ef6a9f2913899bed02f5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
